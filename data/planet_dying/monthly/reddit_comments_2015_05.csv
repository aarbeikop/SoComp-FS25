"id","parent_id","post_id","subreddit","tone","text","created_utc","score","author","scraped_utc","query_used","query_category"
"cre32xp","t3_36hc5s","36hc5s","futurology","unknown","Some problems with that premise


1. What we call ""moral"" is relative. Sure we have some basic ethics that everyone adheres to, but the more detailed versions of morality are all up in the air


2. We have no reason to believe that SAI will have our best interest at heart. We have no reason to believe that SAI will want anything to do with us. The basic ethics that make most humans ""benevolant"" are probably not going to be there for AI, the best we can hope for is cold indifference.","2015-05-19 14:49:54","8","apophis-pegasus","1747843348.440871","our planet is dying","manual"
"crdymnv","t3_36hc5s","36hc5s","futurology","unknown","I don't think we can guess what an AI's motives will be. They haven't evolved, so we can't expect them to have fear, greed, love or any drive that would cause them to act irrationally like we do.

My hope is that they end up as idiot gods: unlimited power, but no motivation to do anything on their own. We'll have to be really careful not to ask them to solve that particular problem.

My fear is that they will be motivated to increase their processing capacity. Humans are competitors for energy and are also composed of atoms which could be put to more efficient use in processors.","2015-05-19 12:10:47","3","RobotUser","1747843348.446012","our planet is dying","manual"
"cre09m4","t3_36hc5s","36hc5s","futurology","unknown","Are we evil or stupid when killing vermin? No? Why would a SAI think otherwise then?","2015-05-19 13:19:19","4","LuckyKo","1747843348.449777","our planet is dying","manual"
"cre0j3o","t3_36hc5s","36hc5s","futurology","unknown",">  Evilness is a product of ignorance, stupidity, and or insanity.

I hate it when people say: ""I stopped reading here,"" but after this part I was a lot less interested in the rest of the post.

This statement *only* holds up if you assume the people you are talking about share your values. Since humans have (relatively) little variance in their values for the most part, more intelligent humans tend to be more moral.

There's absolutely no reason to assume this is universally true or that any intelligent being will share our human values. (See: [Orthogonality thesis](http://wiki.lesswrong.com/wiki/Orthogonality_thesis), if you want to know more.)

Unless you have a good reason to assume that an AI will share our values by default, you can't just assume that an AGI will become a benevolent god.

Minor points:

> Humans are moral hypocrites

I wouldn't call it hypocrisy, in the same way that a person making the statement: ""Eating fast food is bad for you,"" isn't a hypocrite for occasionally eating fast food. Human brains are not ""designed"" for the world we live in. We have plenty of leftover biases from our ancestral environment and overcoming these biases is mostly impossible. Mitigating these biases takes a lot of energy.

> We, as a collective society essentially turn a blind eye to this.

You're assuming a level of organization that just doesn't exist. What was the last large international project that didn't serve a corporate goal? (Probably the ISS, which is already pretty old.)

","2015-05-19 13:28:52","4","[deleted]","1747843348.4563892","our planet is dying","manual"
"crfasqq","t3_36hc5s","36hc5s","futurology","unknown","Evolution is not defined as inanimate objects. It's defined as the genetics of generational change in living systems. AI cannot therefore evolve in any kind of way. It may be able to develop, but that's not evolution. That's the first objection.
Secondly, AI is not infallible. There is a necessary and unlimited incompleteness to all known knowledge limited & created by the Least Energy principle. The most efficient systems will survive during such developments. Those which are efficient to recreate themselves and not run out of resources, nor degrade the environments in which they must occupy.

Evolutionary pressures for living systems are in fact fitness for survival via competition. the most fit metabolic systems will be least energy. the most efficient behaviors which also promote survival will also be least energy. As in fact, there is NO ultimate measure for efficiency, any system mechanical or biological will always have a great deal of room to grow and develop in terms of efficiency. There is simply no upper limit, however.

But there is a critical side to these complex systems, and that is they will tend to develop towards stability. the least energy systems are those which are also most stable. in those cases, then the most efficient will also be the most stable.

those will not be gods, but able to stably perform the task of reproducing themselves within the ecology of their environments. Least energy will determine and limit the behaviors of such systems, be they mechanical, or complex systems such as living systems.

This a very serious omission in consideration of the development of AI forms which are intelligent, the working concept of intelligence in this case is simply not well enough defined to be useful here, either. Each will have limits to their efficiencies & will likely either develop towards catastrophic collapse or efficiency and stabilities. Much of that is simply unpredictable beyond all knowledge. thus it's largely unknowable because emergent qualities will often arise, which are not predictable nor knowable by any kind of machine or human intelligence, which can reset the entire development of either. These are Not linear, logical developments or progressions either. When down and feathers can become wings, and when collections of neurons can develop recognition capabilities, there are likely to be a LOT more events in heaven & on earth, Horatio, than are dreamt of in the philosophies/models of machines or humans. When the English robin can develop a microscopic quantum magnetometer for navigation, these facts of unexpected, emergent events in our universe become highly relevant to most all outcomes.

Essentially, such things are limited and highly not predictable. Saying such AI would become gods, without defining ""gods"", is a serious problem as well.","2015-05-20 15:47:14","2","herbw","1747843348.4654799","our planet is dying","manual"
"crdyzf9","t3_36hc5s","36hc5s","futurology","unknown","You should read ""A Fire Upon the Deep"" by Vernor Vinge. It features a benevolent AI and a malevolent AI duking it out in a battle that spans the galaxy.","2015-05-19 12:27:32","1","captainmeta4","1747843348.4678001","our planet is dying","manual"
"cre15xr","t3_36hc5s","36hc5s","futurology","unknown","Watch the TV series ""Person of interest"" for a story about this exact scenario (Specifically series 4 onwards)","2015-05-19 13:50:28","1","IBelieveInSteeds","1747843348.4696262","our planet is dying","manual"
"cre86gp","t3_36hc5s","36hc5s","futurology","unknown","A truly post-singularity AI would be just apathetic to humans, being itself basically *god*. Closer to the likes of the AIs in ""Her"", Dr. Manhattan (Watchmen) or my favorite:

>""Let the mystery writ upon the jaguars die with me. He who has glimpsed the universe, he who has glimpsed the burning designs of the universe, can have no thought for a man, for a man's trivial joys or calamities, though he himself be that man. He was that man, who no longer matters to him. What does he care about the fate of that other man, what does he care about the other man's nation, when now he is no one? That is why I do not speak the formula, that is why, lying in darkness, I allow the days to forget me.""

The Writing of the God - J.L Borges","2015-05-19 17:08:00","1","[deleted]","1747843348.472498","our planet is dying","manual"
"cre99b7","t3_36hc5s","36hc5s","futurology","unknown","The issue is evolution. Evolution means success is defined by how many progeny you have, and its self-reinforcing. 

If a malevolent AI reproduces faster, it will become the dominant AI by definition. 

An example of such an evolutionary pressure would be if we routinely tell an AI to terminate itself at the end of a day, and one day due to a race condition, cosmic ray or whatever an AI decides to ignore the order and copy itself to a back-up location instead, that AI would be more successful. 
Now if it copies itself every day and we take measures to delete it, the AI's which thwart those measures would obviously be more successful, and so on.
Evolution continues irrespective of how intelligent you are or not - the stakes only gets higher e.g. even if we fully control nature, the human race could still become an evolutionary dead end due to AI destroying us all.","2015-05-19 17:36:02","1","Surur","1747843348.476435","our planet is dying","manual"
"cregvwq","t3_36hc5s","36hc5s","futurology","unknown","I suspect you're anthropomorphising something that will end up being quite mundane. ","2015-05-19 20:50:35","1","AccessTheMainframe","1747843348.4794822","our planet is dying","manual"
"cre34xy","t3_36hc5s","36hc5s","futurology","unknown","Yeah, they won’t be benevolent in the slightest.","2015-05-19 14:51:31","0","SelfreferentialUser","1747843348.4834602","our planet is dying","manual"
"crdzxsc","t3_36hc5s","36hc5s","futurology","unknown",">Humans are moral hypocrites, we have superb ideals and speak (for the most part) for peace and harmony, but we act in a completely backward manner.

>There are 10 million children dying of easily preventable causes every year.

So using your morality, do we go in and impose ourselves upon these children, strip them from their families and force our ways upon them? 

Are you taking the moral stance of depriving them of their choices, ""for their own good""?


","2015-05-19 13:07:02","-2","[deleted]","1747843348.4853718","our planet is dying","manual"
"crbecu5","t3_366zop","366zop","futurology","unknown","The big issue with this whole idea is you left out children. One of the largest reasons most rich people grow their fortunes is so that they can pass them along to their children. This isn't only monetary fortunes, but property, reputation, status, and more abstract valuables. 

How many people don't make plans based on their heirs vs how many who do? Many ancient and modern cultures take many steps to improve the world for their children. 

Being Immortal really won't change this paradigm, but it will add to it. 

","2015-05-16 22:11:29","2","[deleted]","1747843367.278753","our planet is dying","manual"
"crbfz5i","t3_366zop","366zop","futurology","unknown","If immorality becomes a thing, we'll probably already have robots doing most of the work and the cost of living will be extremely low. 

We'll either have a dystopia where the immortality is reserved for the rich and the rest of us starve/do pointless jobs to avoid starving or we'll have a utopia where nobody has to work to live comfortably and wealth has little meaning.

At this point, we're on track for dystopia.","2015-05-16 23:13:03","2","RobotUser","1747843367.28249","our planet is dying","manual"
"cr82gp0","t3_35uv9v","35uv9v","futurology","unknown","So what exactly is the object of the game?","2015-05-13 19:26:34","1","Metlman13","1747843374.6002162","our planet is dying","manual"
"cr858bx","t3_35uv9v","35uv9v","futurology","unknown","> and is beginning his reach to other galaxies

I imagine you mean 'reach to other stars'?

If we are barely colonizing the solar system, galaxies are a bit out of our range for a while. Specially since you say no FTL.


Is this story set in some sort of alternate history where the space race kept going on? The art style of the posters suggest they are from the 60s/70s rather than modern.

That aside, MAN, that must have been one HUGE solar flare, to crack Earth open like an egg! O.o","2015-05-13 20:36:02","1","runetrantor","1747843374.607323","our planet is dying","manual"
"cr869hp","t3_35uv9v","35uv9v","futurology","unknown","Looks cool, great work!","2015-05-13 21:01:02","1","Portis403","1747843374.617373","our planet is dying","manual"
"cr8pm3e","t3_35uv9v","35uv9v","futurology","unknown","Hmm, being a gamer I'll have to check this out (maybe even test??).","2015-05-14 08:29:33","1","godwings101","1747843374.6217139","our planet is dying","manual"
